import torch
import numpy as np
from scipy import signal
import os
import sys
import importlib.util

# --- è·¯å¾„ä¿®å¤ (ç¡®ä¿èƒ½æ‰¾åˆ°ä¸Šçº§ç›®å½•çš„ config å’Œ GetTrainTest-fecg) ---
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.append(parent_dir)

from config import cfg


# åŠ¨æ€åŠ è½½ runner
def dynamic_import(module_name, file_path):
    spec = importlib.util.spec_from_file_location(module_name, file_path)
    module = importlib.util.module_from_spec(spec)
    sys.modules[module_name] = module
    spec.loader.exec_module(module)
    return module


runner = dynamic_import("GetTrainTest-fecg", os.path.join(parent_dir, "GetTrainTest-fecg.py"))
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
runner.DEVICE = DEVICE


class InferenceCore:
    def __init__(self, model_name="addb_mkf2_improved_0_fecg_diff_0.5"):
        print("ğŸ”„ åˆå§‹åŒ–æ¨ç†æ ¸å¿ƒ...")
        self.model = self._load_model(model_name)
        self.params = runner.inference_schedule(self.model)
        self.fs_model = 1000  # æ¨¡å‹éœ€è¦çš„é‡‡æ ·ç‡
        self.fs_raw = 250  # åŸå§‹ TXT æ•°æ®çš„é‡‡æ ·ç‡
        print("âœ… æ¨ç†æ ¸å¿ƒå°±ç»ª")

    def _load_model(self, model_name):
        # å¯»æ‰¾æ¨¡å‹è·¯å¾„
        possible_dirs = [
            os.path.join(parent_dir, "results", "model"),
            os.path.join(parent_dir, "resource", "model"),
            os.path.join(parent_dir, "model")
        ]
        model_dir = next((d for d in possible_dirs if os.path.exists(d)), None)
        if not model_dir: raise FileNotFoundError("Model directory not found")

        if not model_name.endswith(".pt"):
            pt_files = [f for f in os.listdir(model_dir) if f.endswith(".pt")]
            if pt_files: model_name = pt_files[0].replace(".pt", "")

        model = runner.load_model(model_dir=model_dir, model_file=model_name)
        model = model.to(DEVICE)
        model.eval()
        return model

    def strict_preprocessing(self, data):
        """
        [ä¸¥æ ¼é¢„å¤„ç†æµç¨‹] (ä»…ç”¨äºæ¯ä½“å¿ƒç”µçš„æ¸…æ´—ä¸ç½‘é¡µæ˜¾ç¤º)
        1. å‰”é™¤ > 100k çš„åç‚¹
        2. å¸¦é€š 5-50Hz + é™·æ³¢ 50/60Hz
        """
        # 1. åç‚¹å‰”é™¤
        data = np.clip(data, -100000, 100000)

        # 2. æ»¤æ³¢ (åœ¨ 250Hz ä¸‹è¿›è¡Œ)
        # 50Hz é™·æ³¢
        b_notch, a_notch = signal.iirnotch(w0=50.0, Q=30.0, fs=self.fs_raw)
        data = signal.filtfilt(b_notch, a_notch, data)
        # 60Hz é™·æ³¢
        b_notch2, a_notch2 = signal.iirnotch(w0=60.0, Q=30.0, fs=self.fs_raw)
        data = signal.filtfilt(b_notch2, a_notch2, data)

        # 5-50Hz å¸¦é€š
        sos = signal.butter(4, [5, 50], btype='bandpass', fs=self.fs_raw, output='sos')
        data = signal.sosfiltfilt(sos, data)

        return data

    def process_segment(self, raw_segment):
        """
        å¤„ç†ä¸€ä¸ªæ—¶é—´çª—å£çš„æ•°æ®
        Input: raw_segment (numpy array, 250Hz)
        Output: raw_clean (250Hz), fecg_processed (200Hz)
        """
        # ==========================================
        # 1. å‡†å¤‡ç½‘é¡µæ˜¾ç¤ºçš„æ¯ä½“å¿ƒç”µ (Clean Data)
        # ==========================================
        # è¿™é‡Œè¿›è¡Œä¸¥æ ¼æ¸…æ´—ï¼Œä¸ºäº†è®©åŒ»ç”Ÿçœ‹å¾—æ¸…æ¥š
        raw_clean = self.strict_preprocessing(raw_segment)
        raw_clean = raw_clean - np.mean(raw_clean)

        # è®¡ç®—ç¼©æ”¾å› å­ (åŸºäºå¹²å‡€çš„æ¯ä½“ä¿¡å·)
        p1, p99 = np.percentile(raw_clean, [1, 99])
        scale_factor = (p99 - p1) / 2.0
        if scale_factor < 1e-6: scale_factor = 1.0

        # ==========================================
        # 2. å‡†å¤‡ AI æ¨¡å‹è¾“å…¥ (Raw Data)
        # ==========================================
        # ğŸ”¥ã€æ ¸å¿ƒä¿®æ­£ã€‘ï¼šè¿™é‡Œå¿…é¡»ä½¿ç”¨ raw_segment (åŸå§‹å«å™ªæ•°æ®)ï¼
        # å¦‚æœå–‚ç»™æ¨¡å‹ raw_cleanï¼Œæ¨¡å‹ä¼šå› ä¸ºæ•°æ®åˆ†å¸ƒä¸åŒ¹é…è€Œå¤±æ•ˆï¼Œ
        # å¯¼è‡´è¾“å‡ºç»“æœä¹Ÿæ˜¯æ¯ä½“å¿ƒç”µã€‚

        len_raw = len(raw_segment)
        len_model = len_raw * 4

        # ä½¿ç”¨åŸå§‹æ•°æ®é‡é‡‡æ ·
        raw_1k = signal.resample(raw_segment, len_model)

        # å½’ä¸€åŒ– (Z-score) æ˜¯æ¨¡å‹å¿…é¡»çš„
        # Detrend ä¸€ä¸‹é˜²æ­¢æåº¦æ¼‚ç§»å½±å“å½’ä¸€åŒ–ï¼Œä½†ä¸åšå¼ºæ»¤æ³¢
        raw_1k_detrend = signal.detrend(raw_1k)
        model_input_norm = (raw_1k_detrend - np.mean(raw_1k_detrend)) / (np.std(raw_1k_detrend) + 1e-6)

        # æ„é€  Tensor
        inp = np.tile(model_input_norm, (4, 1))
        inp_tensor = torch.from_numpy(inp).float().unsqueeze(0).to(DEVICE)

        # ==========================================
        # 3. æ‰§è¡Œæ¨ç†
        # ==========================================
        with torch.no_grad():
            alpha, beta, alpha_cum, sigmas, T, c1, c2, c3, delta, delta_bar = self.params
            output = runner.predict(self.model, inp_tensor.squeeze(0),
                                    alpha, beta, alpha_cum, sigmas, T,
                                    c1, c2, c3, delta, delta_bar,
                                    device=DEVICE)

        fecg_1k = output[0, :].cpu().numpy()

        # ==========================================
        # 4. åå¤„ç† FECG (æŒ‰æ‚¨çš„æ–°è¦æ±‚)
        # ==========================================

        # (1) å¸¦é€šæ»¤æ³¢ 7.5Hz - 75Hz
        # è¿™ä¸€æ­¥èƒ½æœ‰æ•ˆå»é™¤ç”Ÿæˆçš„ä½é¢‘ä¼ªå½±å’Œæé«˜é¢‘å™ªå£°
        sos_bp = signal.butter(4, [7.5, 75], btype='bandpass', fs=1000, output='sos')
        fecg_filtered = signal.sosfiltfilt(sos_bp, fecg_1k)

        # (2) é‡é‡‡æ ·åˆ° 200Hz
        # ç›®æ ‡ç‚¹æ•° = åŸå§‹æ—¶é—´é•¿åº¦(ç§’) * 200Hz
        target_len = int((len_raw / 250.0) * 200)
        fecg_200 = signal.resample(fecg_filtered, target_len)

        # (3) æ¢å¤å¹…åº¦
        # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†è®© FECG åœ¨ç½‘é¡µä¸Šèƒ½ä»¥ uV ä¸ºå•ä½æ˜¾ç¤º
        fecg_final = (fecg_200 - np.mean(fecg_200)) * scale_factor

        # è¿”å›ï¼š[æ¸…æ´—åçš„æ¯ä½“å¿ƒç”µ], [æå–å‡ºçš„èƒå„¿å¿ƒç”µ]
        return raw_clean, fecg_final