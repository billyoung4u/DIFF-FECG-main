import torch
import numpy as np
from scipy import signal
import os
import sys
import math
import importlib.util

# --- Ê†∏ÂøÉ‰øÆÂ§çÔºöÂ∞ÜÁà∂ÁõÆÂΩïÂä†ÂÖ•Ë∑ØÂæÑ ---
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.append(parent_dir)
# -------------------------------

# ÂºïÂÖ•ÈÖçÁΩÆ
from config import cfg


# ==========================================
# Âä®ÊÄÅÂä†ËΩΩ runner
# ==========================================
def dynamic_import(module_name, file_path):
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Êâæ‰∏çÂà∞Êñá‰ª∂: {file_path}")
    spec = importlib.util.spec_from_file_location(module_name, file_path)
    module = importlib.util.module_from_spec(spec)
    sys.modules[module_name] = module
    spec.loader.exec_module(module)
    return module


# ÊãºÂáë GetTrainTest-fecg.py ÁöÑÁªùÂØπË∑ØÂæÑ
script_path = os.path.join(parent_dir, "GetTrainTest-fecg.py")
runner = dynamic_import("GetTrainTest-fecg", script_path)

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
runner.DEVICE = DEVICE


class FecgInferenceService:
    def __init__(self, model_name="addb_mkf2_improved_0_fecg_diff_0.5"):
        print("üîÑ ÂàùÂßãÂåñÊé®ÁêÜÊúçÂä°...")
        self.model = self._load_model(model_name)
        self.params = runner.inference_schedule(self.model)
        print("‚úÖ DIFF-FECG ÊúçÂä°Â∑≤Â∞±Áª™")

    def _load_model(self, model_name):
        possible_dirs = [os.path.join("results", "model"), os.path.join("resource", "model"), "model"]
        model_dir = next((d for d in possible_dirs if os.path.exists(d)), None)

        if not model_dir:
            raise FileNotFoundError("‚ùå Êâæ‰∏çÂà∞ results/model Êàñ resource/model Êñá‰ª∂Â§π")

        if not model_name.endswith(".pt"):
            pt_files = [f for f in os.listdir(model_dir) if f.endswith(".pt")]
            if pt_files:
                target = next((f for f in pt_files if model_name in f), pt_files[0])
                model_name = target.replace(".pt", "")

        print(f"   -> Âä†ËΩΩÊùÉÈáç: {model_name}")
        model = runner.load_model(model_dir=model_dir, model_file=model_name)
        model = model.to(DEVICE)
        model.eval()
        return model

    def process_single_channel(self, raw_signal_full):
        """
        ÂÖ®ÈáèÂ§ÑÁêÜÂçïÈÄöÈÅì‰ø°Âè∑ÔºåÂåÖÂê´‰∏•Ê†ºÁöÑ 4 Ê≠•ÂêéÂ§ÑÁêÜ
        """
        # 1. ÂáÜÂ§áÊï∞ÊçÆ: 250Hz -> 1000Hz
        len_raw = len(raw_signal_full)
        len_model = len_raw * 4
        raw_1k = signal.resample(raw_signal_full, len_model)

        # 2. ÂàáÁâáÊé®ÁêÜ (Chunking Inference)
        CHUNK_SIZE = 2000
        full_fecg_1k = []
        num_chunks = math.ceil(len_model / CHUNK_SIZE)

        with torch.no_grad():
            alpha, beta, alpha_cum, sigmas, T, c1, c2, c3, delta, delta_bar = self.params

            for i in range(num_chunks):
                start = i * CHUNK_SIZE
                end = min((i + 1) * CHUNK_SIZE, len_model)
                seg = raw_1k[start:end]
                current_seg_len = len(seg)

                if current_seg_len < CHUNK_SIZE:
                    pad_len = CHUNK_SIZE - current_seg_len
                    seg = np.pad(seg, (0, pad_len), 'constant')

                # È¢ÑÂ§ÑÁêÜ (ÂéªÊºÇÁßª+ÂΩí‰∏ÄÂåñÔºåÁî®‰∫éÊ®°ÂûãËæìÂÖ•)
                seg_detrend = signal.detrend(seg)
                mean = np.mean(seg_detrend)
                std = np.std(seg_detrend) + 1e-6
                seg_norm = (seg_detrend - mean) / std

                seg_input = np.tile(seg_norm, (4, 1))
                seg_tensor = torch.from_numpy(seg_input).float().to(DEVICE)

                output = runner.predict(self.model, seg_tensor,
                                        alpha, beta, alpha_cum, sigmas, T,
                                        c1, c2, c3, delta, delta_bar,
                                        device=DEVICE)

                out_numpy = output[0, :].cpu().numpy()

                if current_seg_len < CHUNK_SIZE:
                    out_numpy = out_numpy[:current_seg_len]
                full_fecg_1k.append(out_numpy)

        # ÊãºÊé•ÁªìÊûú (1000Hz)
        full_fecg_1k = np.concatenate(full_fecg_1k)

        # =========================================================
        # üî• Ê†∏ÂøÉ‰øÆÊîπÔºö‰∏•Ê†ºÊâßË°å 4 Ê≠•ÂêéÂ§ÑÁêÜÈÄªËæë
        # =========================================================

        # [Ê≠•È™§ 1] ÂâîÈô§ >100k ÁöÑÂùèÁÇπ (ËôΩÁÑ∂Ê®°ÂûãËæìÂá∫ÈÄöÂ∏∏ËæÉÂ∞èÔºå‰ΩÜËøôËÉΩÈò≤Ê≠¢ÊÑèÂ§ñÁàÜÁÇ∏)
        full_fecg_1k = np.clip(full_fecg_1k, -100000, 100000)

        # [Ê≠•È™§ 2] ÁªÑÂêàÊª§Ê≥¢ (Âú® 1000Hz ‰∏ãËøõË°å‰ª•Ëé∑ÂæóÊõ¥Â•ΩÊïàÊûú)
        # A. 50Hz Èô∑Ê≥¢ (Q=30)
        b_notch, a_notch = signal.iirnotch(w0=50.0, Q=30.0, fs=1000)
        full_fecg_1k = signal.filtfilt(b_notch, a_notch, full_fecg_1k)

        # B. 5-50Hz Â∏¶ÈÄöÊª§Ê≥¢
        # Ê≥®ÊÑèÔºöËøôÈáå‰ΩøÁî® sosfiltfilt ‰øùËØÅÈõ∂Áõ∏‰ΩçÂÅèÁßª
        sos_bp = signal.butter(4, [5, 50], btype='bandpass', fs=1000, output='sos')
        full_fecg_1k = signal.sosfiltfilt(sos_bp, full_fecg_1k)

        # ÈôçÈááÊ†∑Âõû 250Hz (ÂøÖÈ°ªÂú®Êª§Ê≥¢ÂêéËøõË°åÔºåÈò≤Ê≠¢Ê∑∑Âè†)
        full_fecg_250 = signal.resample(full_fecg_1k, len_raw)

        # [Ê≠•È™§ 3] ÂáèÂéªÂÖ®Â±ÄÂùáÂÄº (Á°Æ‰øùÊ≥¢ÂΩ¢Â±Ö‰∏≠)
        full_fecg_250 = full_fecg_250 - np.mean(full_fecg_250)

        # [Ê≠•È™§ 4] ÂøΩÁï•Ââç1%ÂíåÂêé1%ÁöÑÊûÅÂÄºËøõË°åÁº©Êîæ (Ê†áÂáÜÂåñ)
        # Ëøô‰∏ÄÊ≠•Â∞ÜËæìÂá∫Ê≥¢ÂΩ¢ÂΩí‰∏ÄÂåñÔºå‰ΩøÂÖ∂ÂπÖÂ∫¶Âú®‰∏Ä‰∏™Ê†áÂáÜËåÉÂõ¥ÂÜÖÔºå
        # Êñπ‰æø app.py ÈöèÂêéÊ†πÊçÆÂéüÂßã‰ø°Âè∑ÁöÑÂπÖÂ∫¶ËøõË°åÊãâ‰º∏„ÄÇ
        p1, p99 = np.percentile(full_fecg_250, [1, 99])
        robust_amp = (p99 - p1) / 2.0

        if robust_amp > 1e-6:
            full_fecg_250 = full_fecg_250 / robust_amp

        return full_fecg_250